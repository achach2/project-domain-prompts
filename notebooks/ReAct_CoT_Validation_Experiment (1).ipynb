{"cells":[{"cell_type":"markdown","metadata":{"id":"g5svJF-Hi5wr"},"source":["# Experimental Plan: ReAct with Chain of Thought (CoT) for Validation Reports\n","This notebook implements the ReAct framework combined with Chain of Thought (CoT) prompting to generate validation reports.\n","\n","## **Steps:**\n","1. Define validation assessment instructions.\n","2. Implement ReAct with step-by-step reasoning before generating conclusions.\n","3. Evaluate generated validation reports.\n","4. Compare outputs with different prompting techniques.\n"]},{"cell_type":"markdown","source":["### **Experimental Plan to Test ReAct with Chain of Thought (CoT) Prompting for Generating Validation Reports**\n","\n","#### **Objective:**\n","This experiment aims to evaluate the effectiveness of combining the **ReAct** (Reasoning + Acting) prompting technique with **Chain of Thought (CoT)** prompting to generate structured validation reports based on a given set of validation assessment instructions.\n","\n","---\n","\n","### **Experimental Steps:**\n","\n","1. **Define the Validation Assessment Instructions:**\n","   - Select a set of example validation guidelines (e.g., assessing the consistency of model assumptions, evaluating data integrity, verifying model performance).\n","\n","2. **Implement ReAct with Chain of Thought (CoT):**\n","   - Use the **Python ReAct snippet** described in [Simon Willisonâ€™s post](https://til.simonwillison.net/llms/python-react-pattern).\n","   - Modify the ReAct approach to include **step-by-step reasoning** before taking an action.\n","\n","3. **Prompt Structure:**\n","   - Construct prompts that encourage the model to first **explain** its thought process before retrieving additional data or generating conclusions.\n","   - Example prompt:\n","     ```\n","     You are an expert model validator. Your task is to analyze the following validation guideline step by step.\n","     Step 1: Break down the key aspects of the requirement.\n","     Step 2: Retrieve any necessary supporting evidence.\n","     Step 3: Assess the evidence and form a logical conclusion.\n","     Step 4: Generate a structured validation report.\n","     ```\n","\n","4. **Run the Experiment with Different Models:**\n","   - Test the approach using **Llama 3.2 8B** and **GPT-4** to compare results.\n","\n","5. **Evaluate Output Quality:**\n","   - Use automated metrics such as **relevancy, hallucination, groundedness, and comprehensiveness** to assess the quality of the generated reports.\n","   - Compare outputs with human expert reviews.\n","\n","6. **Compare with Standard ReAct:**\n","   - Run the same validation process with **ReAct alone (without CoT)** and compare the quality of reports.\n","\n","7. **Refinement and Iteration:**\n","   - Adjust the prompt structure to optimize the clarity, accuracy, and completeness of the generated validation reports.\n","\n","---\n","\n"],"metadata":{"id":"b23_CD_6i724"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rq_J_X9ti5wu"},"outputs":[],"source":["import openai\n","import json\n","\n","# Set your OpenAI API Key\n","OPENAI_API_KEY = \"your-api-key-here\"\n","openai.api_key = OPENAI_API_KEY\n","\n","# Define the ReAct with Chain of Thought (CoT) Prompt\n","def generate_validation_report(assessment_instruction):\n","    prompt = f\"\"\"\n","    You are an expert model validator. Your task is to generate a validation report using step-by-step reasoning.\n","\n","    Validation Guideline: {assessment_instruction}\n","\n","    Step 1: Identify the key elements of the validation requirement.\n","    Step 2: Retrieve any relevant supporting data from external sources.\n","    Step 3: Evaluate the retrieved information using logical reasoning.\n","    Step 4: Formulate a structured validation report with explanations.\n","\n","    Provide the output in a structured format, including:\n","    - Summary of the assessment\n","    - Supporting evidence\n","    - Final validation decision\n","    - Justification of the decision\n","    \"\"\"\n","\n","    # Send request to OpenAI API (ReAct + CoT)\n","    response = openai.ChatCompletion.create(\n","        model=\"gpt-4\",\n","        messages=[{\"role\": \"system\", \"content\": \"You are a professional AI model validator.\"},\n","                  {\"role\": \"user\", \"content\": prompt}]\n","    )\n","\n","    return response['choices'][0]['message']['content']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfgTKLSai5ww"},"outputs":[],"source":["# Example set of validation assessment instructions\n","validation_instructions = [\n","    \"Assess whether the model assumptions align with business objectives.\",\n","    \"Verify if data preprocessing steps ensure integrity and consistency.\",\n","    \"Evaluate the robustness of the model under different economic scenarios.\"\n","]\n","\n","# Generate validation reports using ReAct + CoT\n","results = {}\n","for instruction in validation_instructions:\n","    results[instruction] = generate_validation_report(instruction)\n","\n","# Save results to JSON file for further analysis\n","with open(\"validation_reports.json\", \"w\") as f:\n","    json.dump(results, f, indent=4)\n","\n","# Display results\n","for instruction, report in results.items():\n","    print(f\"=== Validation Report for: {instruction} ===\")\n","    print(report)\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}